{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_11344/337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDED CONSTANTS\n",
    "SHUFFLE_SEED = 50 # random seed\n",
    "FRAME_RATES = 16000\n",
    "TEST_SPLIT = 0.1 # 10% data for testing model\n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 50\n",
    "SCALE = 0.5\n",
    "DATASET_NOISE_PATH = './data/Noise/'\n",
    "CLASS_NAME= [\"Bao Han\",\"Thanh Chi\",\"Duc Manh\",\"Minh Hieu\",\"Gia Minh\",\"Noise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count all noise files and store the noise directory\n",
    "noise_paths = []\n",
    "for subdir in os.listdir(DATASET_NOISE_PATH):\n",
    "    subdir_path = Path(DATASET_NOISE_PATH) / subdir\n",
    "    if os.path.isdir(subdir_path):\n",
    "        noise_paths += [\n",
    "            os.path.join(subdir_path, filepath)\n",
    "            for filepath in os.listdir(subdir_path)\n",
    "            if filepath.endswith(\".wav\")\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_noise_sample(path):\n",
    "    sample, sampling_rate = tf.audio.decode_wav(\n",
    "        tf.io.read_file(path), desired_channels=1\n",
    "    )\n",
    "    if sampling_rate == FRAME_RATES:\n",
    "        # Number of slices of 16000 each that can be generated from the noise sample\n",
    "        slices = int(sample.shape[0] / FRAME_RATES)\n",
    "        sample = tf.split(sample[: slices * FRAME_RATES], slices)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = []\n",
    "for path in noise_paths:\n",
    "    sample = load_noise_sample(path)\n",
    "    if sample:\n",
    "        noises.extend(sample)\n",
    "noises = tf.stack(noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file name</th>\n",
       "      <th>frames rate</th>\n",
       "      <th>time</th>\n",
       "      <th>labels</th>\n",
       "      <th>ID</th>\n",
       "      <th>directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bao Han</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/split data/Bao Han</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bao Han</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/split data/Bao Han</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bao Han</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/split data/Bao Han</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bao Han</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/split data/Bao Han</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bao Han</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/split data/Bao Han</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file name  frames rate  time   labels  ID                  directory\n",
       "0  10001.wav        16000     1  Bao Han   0  ./data/split data/Bao Han\n",
       "1  10002.wav        16000     1  Bao Han   0  ./data/split data/Bao Han\n",
       "2  10003.wav        16000     1  Bao Han   0  ./data/split data/Bao Han\n",
       "3  10004.wav        16000     1  Bao Han   0  ./data/split data/Bao Han\n",
       "4  10005.wav        16000     1  Bao Han   0  ./data/split data/Bao Han"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "management = pd.read_csv('./management.csv')\n",
    "management.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory =  management['directory']+ '/' +management['file name']\n",
    "data_labels = management.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "14983    5\n",
       "14984    5\n",
       "14985    5\n",
       "14986    5\n",
       "14987    5\n",
       "Name: ID, Length: 14988, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_11344/2143487627.py:2: UserWarning: you are shuffling a 'Series' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  rng.shuffle(data_directory)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_11344/2143487627.py:4: UserWarning: you are shuffling a 'Series' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  rng.shuffle(data_labels)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_11344/2143487627.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rng.shuffle(data_labels)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(SHUFFLE_SEED)\n",
    "rng.shuffle(data_directory)\n",
    "rng = np.random.RandomState(SHUFFLE_SEED)\n",
    "rng.shuffle(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_and_labels_to_dataset(audio_paths, labels):\n",
    "    \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
    "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    return tf.data.Dataset.zip((audio_ds, label_ds))\n",
    "\n",
    "\n",
    "def path_to_audio(path):\n",
    "    \"\"\"Reads and decodes an audio file.\"\"\"\n",
    "    audio = tf.io.read_file(path)\n",
    "    audio, _ = tf.audio.decode_wav(audio, 1, FRAME_RATES)\n",
    "    return audio\n",
    "\n",
    "\n",
    "def add_noise(audio, noises=None, scale=0.5):\n",
    "    if noises is not None:\n",
    "        # Create a random tensor of the same size as audio ranging from\n",
    "        # 0 to the number of noise stream samples that we have.\n",
    "        tf_rnd = tf.random.uniform(\n",
    "            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n",
    "        )\n",
    "        noise = tf.gather(noises, tf_rnd, axis=0)\n",
    "\n",
    "        # Get the amplitude proportion between the audio and the noise\n",
    "        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n",
    "        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n",
    "\n",
    "        # Adding the rescaled noise to audio\n",
    "        audio = audio + noise * prop * scale\n",
    "\n",
    "    return audio\n",
    "\n",
    "\n",
    "def audio_to_fft(audio):\n",
    "    # Since tf.signal.fft applies FFT on the innermost dimension,\n",
    "    # we need to squeeze the dimensions and then expand them again\n",
    "    # after FFT\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    fft = tf.signal.fft(\n",
    "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
    "    )\n",
    "    fft = tf.expand_dims(fft, axis=-1)\n",
    "\n",
    "    # Return the absolute value of the first half of the FFT\n",
    "    # which represents the positive frequencies\n",
    "    return tf.math.abs(fft[:, : (audio.shape[1]), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 13490 files for training.\n",
      "Using 1498 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split into training and validation\n",
    "num_val_samples = int(TEST_SPLIT * len(data_directory))\n",
    "print(\"Using {} files for training.\".format(len(data_directory) - num_val_samples))\n",
    "train_audio_paths = data_directory[:-num_val_samples]\n",
    "train_labels = data_labels[:-num_val_samples]\n",
    "\n",
    "print(\"Using {} files for validation.\".format(num_val_samples))\n",
    "valid_audio_paths = data_directory[-num_val_samples:]\n",
    "valid_labels = data_labels[-num_val_samples:]\n",
    "\n",
    "# Create 2 datasets, one for training and the other for validation\n",
    "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
    "train_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
    "    BATCH_SIZE\n",
    ")\n",
    "\n",
    "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)\n",
    "\n",
    "\n",
    "# Add noise to the training set\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (add_noise(x, noises, scale=SCALE), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "# Transform audio wave to the frequency domain using `audio_to_fft`\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "valid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 16000, 1), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 16000, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 16000, 16)    64          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16000, 16)    0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 16000, 16)    784         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 16000, 16)    32          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16000, 16)    0           conv1d_20[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16000, 16)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 8000, 16)     0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 8000, 32)     1568        max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8000, 32)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 8000, 32)     3104        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 8000, 32)     544         max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8000, 32)     0           conv1d_23[0][0]                  \n",
      "                                                                 conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8000, 32)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 4000, 32)     0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 4000, 64)     6208        max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4000, 64)     0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 4000, 64)     12352       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4000, 64)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 4000, 64)     12352       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 4000, 64)     2112        max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4000, 64)     0           conv1d_27[0][0]                  \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4000, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 2000, 64)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 2000, 128)    24704       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 2000, 128)    0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 2000, 128)    49280       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 2000, 128)    0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 2000, 128)    49280       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 2000, 128)    8320        max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2000, 128)    0           conv1d_31[0][0]                  \n",
      "                                                                 conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 2000, 128)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1000, 128)    0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1000, 128)    49280       max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 1000, 128)    0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1000, 128)    49280       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1000, 128)    0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1000, 128)    49280       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1000, 128)    16512       max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1000, 128)    0           conv1d_35[0][0]                  \n",
      "                                                                 conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 1000, 128)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 500, 128)     0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_1 (AveragePoo (None, 166, 128)     0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 21248)        0           average_pooling1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          5439744     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 6)            774         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,808,470\n",
      "Trainable params: 5,808,470\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, conv_num):\n",
    "    # Shortcut\n",
    "    s = keras.layers.Conv1D(filters, 1, padding=\"same\")(x)\n",
    "    for i in range(conv_num - 1):\n",
    "        x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "    x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
    "    x = keras.layers.Add()([x, s])\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "    return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = keras.layers.Input(shape=input_shape, name=\"input\")\n",
    "\n",
    "    x = residual_block(inputs, 16, 2)\n",
    "    x = residual_block(x, 32, 2)\n",
    "    x = residual_block(x, 64, 3)\n",
    "    x = residual_block(x, 128, 3)\n",
    "    x = residual_block(x, 128, 3)\n",
    "\n",
    "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n",
    "\n",
    "    return keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "model = build_model((FRAME_RATES , 1), len(CLASS_NAME))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model using Adam's default learning rate\n",
    "model.compile(\n",
    "    optimizer=\"SGD\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Add callbacks:\n",
    "# 'EarlyStopping' to stop training when the model is not enhancing anymore\n",
    "# 'ModelCheckPoint' to always keep the model that has the best val_accuracy\n",
    "model_save_filename = \"model.h5\"\n",
    "\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    model_save_filename, monitor=\"val_accuracy\", save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "270/270 [==============================] - 151s 425ms/step - loss: 1.0558 - accuracy: 0.6299 - val_loss: 0.6565 - val_accuracy: 0.8224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\code\\python\\Anaconda\\envs\\test\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "270/270 [==============================] - 70s 257ms/step - loss: 0.6023 - accuracy: 0.8040 - val_loss: 0.4252 - val_accuracy: 0.8652\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 70s 258ms/step - loss: 0.4280 - accuracy: 0.8543 - val_loss: 0.4067 - val_accuracy: 0.8758\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 70s 259ms/step - loss: 0.3392 - accuracy: 0.8862 - val_loss: 0.4408 - val_accuracy: 0.8638\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 70s 260ms/step - loss: 0.3004 - accuracy: 0.8965 - val_loss: 0.3090 - val_accuracy: 0.9126\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 70s 260ms/step - loss: 0.2703 - accuracy: 0.9074 - val_loss: 0.2975 - val_accuracy: 0.9126\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 70s 259ms/step - loss: 0.2397 - accuracy: 0.9192 - val_loss: 0.2381 - val_accuracy: 0.9366\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 70s 260ms/step - loss: 0.2188 - accuracy: 0.9250 - val_loss: 0.2537 - val_accuracy: 0.9132\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 70s 260ms/step - loss: 0.2074 - accuracy: 0.9292 - val_loss: 0.2436 - val_accuracy: 0.9192\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.1855 - accuracy: 0.9367 - val_loss: 0.2695 - val_accuracy: 0.9212\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 70s 260ms/step - loss: 0.1757 - accuracy: 0.9386 - val_loss: 0.2317 - val_accuracy: 0.9393\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.1719 - accuracy: 0.9408 - val_loss: 0.1974 - val_accuracy: 0.9433\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.1592 - accuracy: 0.9465 - val_loss: 0.1955 - val_accuracy: 0.9419\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 70s 260ms/step - loss: 0.1494 - accuracy: 0.9479 - val_loss: 0.1781 - val_accuracy: 0.9453\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.1395 - accuracy: 0.9509 - val_loss: 0.1855 - val_accuracy: 0.9419\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.1339 - accuracy: 0.9526 - val_loss: 0.1631 - val_accuracy: 0.9519\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.1297 - accuracy: 0.9560 - val_loss: 0.1650 - val_accuracy: 0.9499\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.1197 - accuracy: 0.9580 - val_loss: 0.2127 - val_accuracy: 0.9419\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.1095 - accuracy: 0.9618 - val_loss: 0.2643 - val_accuracy: 0.9312\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.1124 - accuracy: 0.9627 - val_loss: 0.1761 - val_accuracy: 0.9506\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.1060 - accuracy: 0.9630 - val_loss: 0.2379 - val_accuracy: 0.9319\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 71s 261ms/step - loss: 0.1034 - accuracy: 0.9637 - val_loss: 0.1501 - val_accuracy: 0.9559\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 71s 261ms/step - loss: 0.0994 - accuracy: 0.9659 - val_loss: 0.1568 - val_accuracy: 0.9539\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.0981 - accuracy: 0.9672 - val_loss: 0.1923 - val_accuracy: 0.9446\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.1028 - accuracy: 0.9650 - val_loss: 0.1266 - val_accuracy: 0.9646\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.0859 - accuracy: 0.9712 - val_loss: 0.1994 - val_accuracy: 0.9493\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.0920 - accuracy: 0.9701 - val_loss: 0.1577 - val_accuracy: 0.9579\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 71s 260ms/step - loss: 0.0842 - accuracy: 0.9713 - val_loss: 0.1807 - val_accuracy: 0.9559\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 72s 267ms/step - loss: 0.0796 - accuracy: 0.9722 - val_loss: 0.1343 - val_accuracy: 0.9606\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 73s 267ms/step - loss: 0.0770 - accuracy: 0.9746 - val_loss: 0.1432 - val_accuracy: 0.9566\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 73s 269ms/step - loss: 0.0712 - accuracy: 0.9749 - val_loss: 0.1059 - val_accuracy: 0.9686\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 73s 268ms/step - loss: 0.0668 - accuracy: 0.9772 - val_loss: 0.1659 - val_accuracy: 0.9606\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 73s 268ms/step - loss: 0.0729 - accuracy: 0.9744 - val_loss: 0.1232 - val_accuracy: 0.9720\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 71s 261ms/step - loss: 0.0636 - accuracy: 0.9789 - val_loss: 0.1531 - val_accuracy: 0.9686\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 71s 261ms/step - loss: 0.0735 - accuracy: 0.9743 - val_loss: 0.1516 - val_accuracy: 0.9633\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 71s 261ms/step - loss: 0.0766 - accuracy: 0.9726 - val_loss: 0.1301 - val_accuracy: 0.9686\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 71s 262ms/step - loss: 0.1032 - accuracy: 0.9701 - val_loss: 0.1570 - val_accuracy: 0.9619\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 73s 268ms/step - loss: 0.0695 - accuracy: 0.9760 - val_loss: 0.1290 - val_accuracy: 0.9646\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 73s 270ms/step - loss: 0.0689 - accuracy: 0.9766 - val_loss: 0.1309 - val_accuracy: 0.9680\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 73s 268ms/step - loss: 0.0567 - accuracy: 0.9807 - val_loss: 0.1493 - val_accuracy: 0.9626\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 73s 268ms/step - loss: 0.0589 - accuracy: 0.9792 - val_loss: 0.1814 - val_accuracy: 0.9640\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 73s 268ms/step - loss: 0.0560 - accuracy: 0.9809 - val_loss: 0.1382 - val_accuracy: 0.9733\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 73s 269ms/step - loss: 0.0575 - accuracy: 0.9788 - val_loss: 0.1742 - val_accuracy: 0.9706\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 73s 269ms/step - loss: 0.0493 - accuracy: 0.9821 - val_loss: 0.1632 - val_accuracy: 0.9646\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 73s 268ms/step - loss: 0.0666 - accuracy: 0.9772 - val_loss: 0.1459 - val_accuracy: 0.9640\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 73s 268ms/step - loss: 0.0631 - accuracy: 0.9789 - val_loss: 0.1382 - val_accuracy: 0.9693\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 73s 268ms/step - loss: 0.0513 - accuracy: 0.9821 - val_loss: 0.1527 - val_accuracy: 0.9706\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 73s 268ms/step - loss: 0.0475 - accuracy: 0.9835 - val_loss: 0.1783 - val_accuracy: 0.9660\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 73s 268ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 0.1451 - val_accuracy: 0.9733\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 73s 268ms/step - loss: 0.0416 - accuracy: 0.9861 - val_loss: 0.1959 - val_accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"./model/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./model/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9881ef05cb6b21837272acdd16fefc950e9e693fbb3274f44385e730a0ff5b69"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
