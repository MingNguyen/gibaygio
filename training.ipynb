{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDED CONSTANTS\n",
    "SHUFFLE_SEED = 50 # random seed\n",
    "FRAME_RATES = 16000\n",
    "TEST_SPLIT = 0.1 # 10% data for testing model\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 50\n",
    "SCALE = 0.5\n",
    "DATASET_NOISE_PATH = './data/Noise/'\n",
    "CLASS_NAME= [\"Bao Han\",\"Thanh Chi\",\"Duc Manh\",\"Minh Hieu\",\"Gia Minh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count all noise files and store the noise directory\n",
    "noise_paths = []\n",
    "for subdir in os.listdir(DATASET_NOISE_PATH):\n",
    "    subdir_path = Path(DATASET_NOISE_PATH) / subdir\n",
    "    if os.path.isdir(subdir_path):\n",
    "        noise_paths += [\n",
    "            os.path.join(subdir_path, filepath)\n",
    "            for filepath in os.listdir(subdir_path)\n",
    "            if filepath.endswith(\".wav\")\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_noise_sample(path):\n",
    "    sample, sampling_rate = tf.audio.decode_wav(\n",
    "        tf.io.read_file(path), desired_channels=1\n",
    "    )\n",
    "    if sampling_rate == FRAME_RATES:\n",
    "        # Number of slices of 16000 each that can be generated from the noise sample\n",
    "        slices = int(sample.shape[0] / FRAME_RATES)\n",
    "        sample = tf.split(sample[: slices * FRAME_RATES], slices)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = []\n",
    "for path in noise_paths:\n",
    "    sample = load_noise_sample(path)\n",
    "    if sample:\n",
    "        noises.extend(sample)\n",
    "noises = tf.stack(noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file name</th>\n",
       "      <th>frames rate</th>\n",
       "      <th>time</th>\n",
       "      <th>labels</th>\n",
       "      <th>ID</th>\n",
       "      <th>directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bao Han</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/split data/Bao Han</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bao Han</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/split data/Bao Han</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bao Han</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/split data/Bao Han</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bao Han</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/split data/Bao Han</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bao Han</td>\n",
       "      <td>0</td>\n",
       "      <td>./data/split data/Bao Han</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file name  frames rate  time   labels  ID                  directory\n",
       "0  10001.wav        16000     1  Bao Han   0  ./data/split data/Bao Han\n",
       "1  10002.wav        16000     1  Bao Han   0  ./data/split data/Bao Han\n",
       "2  10003.wav        16000     1  Bao Han   0  ./data/split data/Bao Han\n",
       "3  10004.wav        16000     1  Bao Han   0  ./data/split data/Bao Han\n",
       "4  10005.wav        16000     1  Bao Han   0  ./data/split data/Bao Han"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "management = pd.read_csv('./management.csv')\n",
    "management.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory =  management['directory']+ '/' +management['file name']\n",
    "data_labels = management.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5995    4\n",
       "5996    4\n",
       "5997    4\n",
       "5998    4\n",
       "5999    4\n",
       "Name: ID, Length: 6000, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\code\\python\\resource\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: UserWarning: `x` isn't a recognized object; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_2804/2143487627.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rng.shuffle(data_labels)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(SHUFFLE_SEED)\n",
    "rng.shuffle(data_directory)\n",
    "rng = np.random.RandomState(SHUFFLE_SEED)\n",
    "rng.shuffle(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_and_labels_to_dataset(audio_paths, labels):\n",
    "    \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
    "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    return tf.data.Dataset.zip((audio_ds, label_ds))\n",
    "\n",
    "\n",
    "def path_to_audio(path):\n",
    "    \"\"\"Reads and decodes an audio file.\"\"\"\n",
    "    audio = tf.io.read_file(path)\n",
    "    audio, _ = tf.audio.decode_wav(audio, 1, FRAME_RATES)\n",
    "    return audio\n",
    "\n",
    "\n",
    "def add_noise(audio, noises=None, scale=0.5):\n",
    "    if noises is not None:\n",
    "        # Create a random tensor of the same size as audio ranging from\n",
    "        # 0 to the number of noise stream samples that we have.\n",
    "        tf_rnd = tf.random.uniform(\n",
    "            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n",
    "        )\n",
    "        noise = tf.gather(noises, tf_rnd, axis=0)\n",
    "\n",
    "        # Get the amplitude proportion between the audio and the noise\n",
    "        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n",
    "        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n",
    "\n",
    "        # Adding the rescaled noise to audio\n",
    "        audio = audio + noise * prop * scale\n",
    "\n",
    "    return audio\n",
    "\n",
    "\n",
    "def audio_to_fft(audio):\n",
    "    # Since tf.signal.fft applies FFT on the innermost dimension,\n",
    "    # we need to squeeze the dimensions and then expand them again\n",
    "    # after FFT\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    fft = tf.signal.fft(\n",
    "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
    "    )\n",
    "    fft = tf.expand_dims(fft, axis=-1)\n",
    "\n",
    "    # Return the absolute value of the first half of the FFT\n",
    "    # which represents the positive frequencies\n",
    "    return tf.math.abs(fft[:, : (audio.shape[1]), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5400 files for training.\n",
      "Using 600 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split into training and validation\n",
    "num_val_samples = int(TEST_SPLIT * len(data_directory))\n",
    "print(\"Using {} files for training.\".format(len(data_directory) - num_val_samples))\n",
    "train_audio_paths = data_directory[:-num_val_samples]\n",
    "train_labels = data_labels[:-num_val_samples]\n",
    "\n",
    "print(\"Using {} files for validation.\".format(num_val_samples))\n",
    "valid_audio_paths = data_directory[-num_val_samples:]\n",
    "valid_labels = data_labels[-num_val_samples:]\n",
    "\n",
    "# Create 2 datasets, one for training and the other for validation\n",
    "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
    "train_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
    "    BATCH_SIZE\n",
    ")\n",
    "\n",
    "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)\n",
    "\n",
    "\n",
    "# Add noise to the training set\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (add_noise(x, noises, scale=SCALE), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "# Transform audio wave to the frequency domain using `audio_to_fft`\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "valid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 16000, 1), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 16000, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 16000, 16)    64          ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 16000, 16)    0           ['conv1d_37[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 16000, 16)    784         ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 16000, 16)    32          ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 16000, 16)    0           ['conv1d_38[0][0]',              \n",
      "                                                                  'conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 16000, 16)    0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_10 (MaxPooling1D  (None, 8000, 16)    0           ['activation_27[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 8000, 32)     1568        ['max_pooling1d_10[0][0]']       \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 8000, 32)     0           ['conv1d_40[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 8000, 32)     3104        ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 8000, 32)     544         ['max_pooling1d_10[0][0]']       \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 8000, 32)     0           ['conv1d_41[0][0]',              \n",
      "                                                                  'conv1d_39[0][0]']              \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 8000, 32)     0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_11 (MaxPooling1D  (None, 4000, 32)    0           ['activation_29[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 4000, 64)     6208        ['max_pooling1d_11[0][0]']       \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 4000, 64)     0           ['conv1d_43[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 4000, 64)     12352       ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 4000, 64)     0           ['conv1d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 4000, 64)     12352       ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 4000, 64)     2112        ['max_pooling1d_11[0][0]']       \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 4000, 64)     0           ['conv1d_45[0][0]',              \n",
      "                                                                  'conv1d_42[0][0]']              \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 4000, 64)     0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_12 (MaxPooling1D  (None, 2000, 64)    0           ['activation_32[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 2000, 128)    24704       ['max_pooling1d_12[0][0]']       \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 2000, 128)    0           ['conv1d_47[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)             (None, 2000, 128)    49280       ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 2000, 128)    0           ['conv1d_48[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)             (None, 2000, 128)    49280       ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 2000, 128)    8320        ['max_pooling1d_12[0][0]']       \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 2000, 128)    0           ['conv1d_49[0][0]',              \n",
      "                                                                  'conv1d_46[0][0]']              \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 2000, 128)    0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_13 (MaxPooling1D  (None, 1000, 128)   0           ['activation_35[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)             (None, 1000, 128)    49280       ['max_pooling1d_13[0][0]']       \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 1000, 128)    0           ['conv1d_51[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_52 (Conv1D)             (None, 1000, 128)    49280       ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 1000, 128)    0           ['conv1d_52[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_53 (Conv1D)             (None, 1000, 128)    49280       ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)             (None, 1000, 128)    16512       ['max_pooling1d_13[0][0]']       \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 1000, 128)    0           ['conv1d_53[0][0]',              \n",
      "                                                                  'conv1d_50[0][0]']              \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 1000, 128)    0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_14 (MaxPooling1D  (None, 500, 128)    0           ['activation_38[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " average_pooling1d_2 (AveragePo  (None, 166, 128)    0           ['max_pooling1d_14[0][0]']       \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 21248)        0           ['average_pooling1d_2[0][0]']    \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          5439744     ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          32896       ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 5)            645         ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,808,341\n",
      "Trainable params: 5,808,341\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, conv_num):\n",
    "    # Shortcut\n",
    "    s = keras.layers.Conv1D(filters, 1, padding=\"same\")(x)\n",
    "    for i in range(conv_num - 1):\n",
    "        x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
    "        x = keras.layers.Activation(\"relu\")(x)\n",
    "    x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
    "    x = keras.layers.Add()([x, s])\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "    return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = keras.layers.Input(shape=input_shape, name=\"input\")\n",
    "\n",
    "    x = residual_block(inputs, 16, 2)\n",
    "    x = residual_block(x, 32, 2)\n",
    "    x = residual_block(x, 64, 3)\n",
    "    x = residual_block(x, 128, 3)\n",
    "    x = residual_block(x, 128, 3)\n",
    "\n",
    "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n",
    "\n",
    "    return keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "model = build_model((FRAME_RATES , 1), len(CLASS_NAME))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model using Adam's default learning rate\n",
    "model.compile(\n",
    "    optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Add callbacks:\n",
    "# 'EarlyStopping' to stop training when the model is not enhancing anymore\n",
    "# 'ModelCheckPoint' to always keep the model that has the best val_accuracy\n",
    "model_save_filename = \"model.h5\"\n",
    "\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    model_save_filename, monitor=\"val_accuracy\", save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 9/54 [====>.........................] - ETA: 2:35 - loss: 3.3536 - accuracy: 0.2867"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2804/1396217893.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearlystopping_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdlcheckpoint_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\python\\resource\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\python\\resource\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\python\\resource\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\python\\resource\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\python\\resource\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\python\\resource\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\python\\resource\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\code\\python\\resource\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\python\\resource\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9881ef05cb6b21837272acdd16fefc950e9e693fbb3274f44385e730a0ff5b69"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
